'use client'

import { useEffect, useRef, useState, useCallback } from 'react'
import { Button } from './ui/button'

interface SimpleSTTProps {
  sessionId: string
  onTranscriptUpdate: (transcript: string, isPartial: boolean) => void
  onError: (error: string) => void
  lang?: string
}

export function SimpleSTT({ sessionId, onTranscriptUpdate, onError, lang = 'en-US' }: SimpleSTTProps) {
  const [isRecording, setIsRecording] = useState(false)
  const [hasPermission, setHasPermission] = useState(false)
  const [status, setStatus] = useState('Initializing...')
  const [chunkCount, setChunkCount] = useState(0) // ğŸ†• ì‹¤ì‹œê°„ ì²­í¬ ì¹´ìš´í„°
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const streamRef = useRef<MediaStream | null>(null)
  const audioChunksRef = useRef<Blob[]>([])
  const isProcessingRef = useRef(false)

  // ğŸ¤ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
  const requestPermission = useCallback(async () => {
    try {
      console.log('ğŸ¤ Requesting microphone permission...')
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 16000,
          channelCount: 1,
        },
      })
      
      stream.getTracks().forEach(track => track.stop())
      setHasPermission(true)
      setStatus('Permission granted')
      console.log('âœ… Microphone permission granted')
      return true
    } catch (error) {
      console.error('âŒ Microphone permission denied:', error)
      setStatus('Permission denied')
      onError('Microphone permission denied')
      return false
    }
  }, [onError])

  // ğŸ§¹ ì •ë¦¬ í•¨ìˆ˜
  const cleanup = useCallback(() => {
    console.log('ğŸ§¹ Cleaning up Simple STT...')
    
    if (mediaRecorderRef.current) {
      if (mediaRecorderRef.current.state !== 'inactive') {
        mediaRecorderRef.current.stop()
      }
      mediaRecorderRef.current = null
    }

    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop())
      streamRef.current = null
    }

          audioChunksRef.current = []
      setChunkCount(0) // ğŸ†• ì²­í¬ ì¹´ìš´í„° ë¦¬ì…‹
      setIsRecording(false)
  }, [])

  // ğŸµ ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬
  const processAudioChunk = useCallback(async () => {
    if (audioChunksRef.current.length === 0 || isProcessingRef.current) return

    isProcessingRef.current = true
    console.log('ğŸµ Processing audio chunk...')

    try {
      // ê°€ì¥ ì•ˆì •ì ì¸ í˜•ì‹ ì‚¬ìš©
      const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' })
      audioChunksRef.current = []
      
      console.log(`ğŸ“Š Audio blob: ${audioBlob.size} bytes, type: ${audioBlob.type}`)
      
      if (audioBlob.size < 1000) {
        console.log('âš ï¸ Audio too small, skipping...')
        return
      }

      // Whisper API í˜¸ì¶œ
      const formData = new FormData()
      formData.append('audio', audioBlob, 'audio.webm')
      formData.append('sessionId', sessionId)
      formData.append('language', lang)
      formData.append('model', 'whisper-1')
      formData.append('response_format', 'verbose_json')
      formData.append('temperature', '0')
      formData.append('prompt', 'This is a lecture or presentation. Focus on clear speech.')
      formData.append('enableGrammarCheck', 'true')

      const response = await fetch('/api/stt', {
        method: 'POST',
        body: formData,
      })

      if (!response.ok) {
        throw new Error(`STT API failed: ${response.status}`)
      }

      const result = await response.json()
      console.log('âœ… STT result:', result)

      if (result.transcript && result.transcript.trim()) {
        console.log('ğŸ“ Updating transcript:', result.transcript.trim())
        onTranscriptUpdate(result.transcript.trim(), false)
      } else {
        console.log('âš ï¸ No transcript in result:', result)
      }
    } catch (error) {
      console.error('âŒ STT processing failed:', error)
      onError('STT processing failed')
    } finally {
      isProcessingRef.current = false
    }
  }, [sessionId, lang, onTranscriptUpdate, onError])

  // ğŸ¤ ë…¹ìŒ ì‹œì‘
  const startRecording = useCallback(async () => {
    if (isRecording) return

    try {
      // ê¶Œí•œ í™•ì¸
      if (!hasPermission) {
        const granted = await requestPermission()
        if (!granted) return
      }

      // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ê°€ì ¸ì˜¤ê¸°
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 16000,
          channelCount: 1,
        },
      })

      streamRef.current = stream

      // MediaRecorder ì„¤ì •
      const options = { 
        mimeType: 'audio/webm;codecs=opus',
        audioBitsPerSecond: 16000
      }
      
      mediaRecorderRef.current = new MediaRecorder(stream, options)
      
      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          console.log(`ğŸµ Chunk: ${event.data.size} bytes`)
          audioChunksRef.current.push(event.data)
          setChunkCount(prev => prev + 1) // ğŸ†• ì‹¤ì‹œê°„ ì¹´ìš´í„° ì—…ë°ì´íŠ¸
        }
      }

      mediaRecorderRef.current.onstop = () => {
        console.log('ğŸ›‘ Recording stopped, processing final chunk...')
        processAudioChunk()
      }

      // 2ì´ˆë§ˆë‹¤ ì²­í¬ ìƒì„± (ë” ë¹ ë¥¸ í”¼ë“œë°±)
      mediaRecorderRef.current.start(2000)
      setIsRecording(true)
      setStatus('Recording...')
      setChunkCount(0) // ì¹´ìš´í„° ë¦¬ì…‹
      
      console.log('âœ… Simple STT recording started')

    } catch (error) {
      console.error('âŒ Failed to start recording:', error)
      setStatus('Failed to start')
      onError('Failed to start recording')
    }
  }, [hasPermission, isRecording, requestPermission, processAudioChunk, onError])

  // ğŸ›‘ ë…¹ìŒ ì¤‘ì§€
  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop()
      setIsRecording(false)
      setStatus('Ready')
      console.log('ğŸ›‘ Simple STT recording stopped')
    }
  }, [isRecording])

  // ğŸ§¹ ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      cleanup()
    }
  }, [cleanup])

  if (!hasPermission) {
    return (
      <div className="flex flex-col gap-4 p-4 border rounded-lg">
        <div className="text-sm text-gray-600">{status}</div>
        <Button onClick={requestPermission} className="bg-blue-500 hover:bg-blue-600">
          ğŸ¤ Grant Microphone Permission
        </Button>
      </div>
    )
  }

  return (
    <div className="flex flex-col gap-4 p-4 border rounded-lg">
      <div className="flex items-center gap-4">
        <Button
          onClick={isRecording ? stopRecording : startRecording}
          className={isRecording ? 'bg-red-500 hover:bg-red-600' : 'bg-green-500 hover:bg-green-600'}
        >
          {isRecording ? 'ğŸ›‘ Stop' : 'ğŸ¤ Start'} Simple STT
        </Button>
        
        <div className="text-sm text-gray-600">
          {isRecording ? 'ğŸ”´ Recording...' : 'âšª Ready'}
        </div>
      </div>
      
      <div className="text-xs text-gray-500">
        <div>Status: {status}</div>
        <div>Chunks: {chunkCount}</div>
        <div>Processing: {isProcessingRef.current ? 'Yes' : 'No'}</div>
        <div>Session ID: {sessionId.substring(0, 8)}...</div>
      </div>
    </div>
  )
} 